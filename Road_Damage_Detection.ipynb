{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "49d4b0e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "49d4b0e4",
        "outputId": "6e3b8245-a079-441e-aca5-e8f20798d9e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload kaggle.json (Kaggle -> Account -> Create New API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4d8d1197-613b-461c-bb45-b1c6e7ee16d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4d8d1197-613b-461c-bb45-b1c6e7ee16d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Kaggle API configured.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Upload kaggle.json (Kaggle -> Account -> Create New API Token)\")\n",
        "_ = files.upload()\n",
        "\n",
        "import os, zipfile\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "!mv kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "print(\"Kaggle API configured.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6be2f73f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6be2f73f",
        "outputId": "133cc2f1-92a4-46b7-a20a-2b6197ee89cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset-1: alvarobasily/road-damage\n",
            "Dataset URL: https://www.kaggle.com/datasets/alvarobasily/road-damage\n",
            "License(s): CC0-1.0\n",
            "Downloading Dataset-2: lorenzoarcioni/road-damage-dataset-potholes-cracks-and-manholes\n",
            "Dataset URL: https://www.kaggle.com/datasets/lorenzoarcioni/road-damage-dataset-potholes-cracks-and-manholes\n",
            "License(s): MIT\n",
            "Unzipping: /content/data1/road-damage.zip\n",
            "Unzipping: /content/data2/road-damage-dataset-potholes-cracks-and-manholes.zip\n",
            "Unzipped.\n"
          ]
        }
      ],
      "source": [
        "DATA1 = \"/content/data1\"\n",
        "DATA2 = \"/content/data2\"\n",
        "import os, zipfile\n",
        "os.makedirs(DATA1, exist_ok=True)\n",
        "os.makedirs(DATA2, exist_ok=True)\n",
        "\n",
        "print(\"Downloading Dataset-1: alvarobasily/road-damage\")\n",
        "!kaggle datasets download -d alvarobasily/road-damage -p $DATA1 -q --force\n",
        "print(\"Downloading Dataset-2: lorenzoarcioni/road-damage-dataset-potholes-cracks-and-manholes\")\n",
        "!kaggle datasets download -d lorenzoarcioni/road-damage-dataset-potholes-cracks-and-manholes -p $DATA2 -q --force\n",
        "\n",
        "def unzip_all(root):\n",
        "    for fn in os.listdir(root):\n",
        "        if fn.lower().endswith(\".zip\"):\n",
        "            path = os.path.join(root, fn)\n",
        "            print(\"Unzipping:\", path)\n",
        "            with zipfile.ZipFile(path, 'r') as z:\n",
        "                z.extractall(root)\n",
        "\n",
        "unzip_all(DATA1); unzip_all(DATA2)\n",
        "print(\"Unzipped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"DATASET 1 STRUCTURE:\")\n",
        "for root, dirs, files in os.walk(\"/content/data1\"):\n",
        "    print(\"Folder: \", root, \"| subfolders:\", dirs[:3], \"| files:\", len(files))\n",
        "    if len(files) > 0 and any(f.lower().endswith(('.jpg','.jpeg','.png')) for f in files):\n",
        "        print(\" Found images here:\", root)\n",
        "\n",
        "print(\"\\nDATASET 2 STRUCTURE:\")\n",
        "for root, dirs, files in os.walk(\"/content/data2\"):\n",
        "    print(\"Folder: \", root, \"| subfolders:\", dirs[:3], \"| files:\", len(files))\n",
        "    if len(files) > 0 and any(f.lower().endswith(('.jpg','.jpeg','.png')) for f in files):\n",
        "        print(\" Found images here:\", root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPS2UPhRnB92",
        "outputId": "2874b600-7af8-487e-8a57-094592834d0f"
      },
      "id": "lPS2UPhRnB92",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET 1 STRUCTURE:\n",
            "Folder:  /content/data1 | subfolders: [] | files: 6644\n",
            " Found images here: /content/data1\n",
            "\n",
            "DATASET 2 STRUCTURE:\n",
            "Folder:  /content/data2 | subfolders: ['data'] | files: 1\n",
            "Folder:  /content/data2/data | subfolders: ['labels', 'images'] | files: 0\n",
            "Folder:  /content/data2/data/labels | subfolders: [] | files: 2009\n",
            "Folder:  /content/data2/data/images | subfolders: [] | files: 2009\n",
            " Found images here: /content/data2/data/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "SMALL1 = \"/content/work_ds1\"\n",
        "SMALL2 = \"/content/work_ds2\"\n",
        "\n",
        "\n",
        "path_ds1 = \"/content/data1\"\n",
        "path_ds2 = \"/content/data2/data/images\"\n",
        "\n",
        "def prepare_small_dataset(src_dir, dst_dir, max_classes=3, limit_per_class=30):\n",
        "    \"\"\"\n",
        "    Create a smaller version of the dataset for quick training or testing.\n",
        "    \"\"\"\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    img_files = glob.glob(os.path.join(src_dir, \"*.jpg\")) + glob.glob(os.path.join(src_dir, \"*.jpeg\"))\n",
        "    if not img_files:\n",
        "        print(f\"No .jpg or .jpeg files found in {src_dir}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    print(f\" Preparing dataset from: {src_dir}\")\n",
        "    cls_dirs = sorted([d for d in os.listdir(src_dir) if os.path.isdir(os.path.join(src_dir, d))])\n",
        "    if not cls_dirs:\n",
        "        cls_dirs = [\"_flat_\"]\n",
        "\n",
        "    for cls_name in cls_dirs[:max_classes]:\n",
        "        src_cls = os.path.join(src_dir, cls_name)\n",
        "        dst_cls = os.path.join(dst_dir, cls_name)\n",
        "        os.makedirs(dst_cls, exist_ok=True)\n",
        "\n",
        "\n",
        "        if cls_name == \"_flat_\":\n",
        "            files = img_files[:limit_per_class]\n",
        "        else:\n",
        "            files = glob.glob(os.path.join(src_cls, \"*.jpg\")) + glob.glob(os.path.join(src_cls, \"*.jpeg\"))\n",
        "            files = files[:limit_per_class]\n",
        "\n",
        "        for f in tqdm(files, desc=f\"Copying {cls_name}\"):\n",
        "            shutil.copy(f, dst_cls)\n",
        "\n",
        "    print(f\" Small dataset created at {dst_dir}\")\n",
        "\n",
        "\n",
        "prepare_small_dataset(path_ds1, SMALL1, max_classes=3, limit_per_class=30)\n",
        "prepare_small_dataset(path_ds2, SMALL2, max_classes=3, limit_per_class=30)\n",
        "\n",
        "print(\"Small subsets successfully created at:\")\n",
        "print(\" -\", SMALL1)\n",
        "print(\" -\", SMALL2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufGyq20OnIKP",
        "outputId": "6fa991c7-298d-4fc4-fb79-a734e0ad0c9b"
      },
      "id": "ufGyq20OnIKP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Preparing dataset from: /content/data1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying _flat_: 100%|██████████| 30/30 [00:00<00:00, 1144.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Small dataset created at /content/work_ds1\n",
            " Preparing dataset from: /content/data2/data/images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying _flat_: 100%|██████████| 30/30 [00:00<00:00, 2815.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Small dataset created at /content/work_ds2\n",
            "Small subsets successfully created at:\n",
            " - /content/work_ds1\n",
            " - /content/work_ds2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ff315230",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff315230",
        "outputId": "72da32da-c58a-41a4-888c-285cca694164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only 1 class detected in '/content/work_ds1/train'.\n",
            "Only 1 class detected in '/content/work_ds1/val'.\n",
            "Only 1 class detected in '/content/work_ds1/test'.\n",
            " Dataset has only one class. Let's check folder structure:\n",
            "['data1']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, cv2, os, seaborn as sns, matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def load_split_arrays(split_dir, img_size=(96,96)):\n",
        "    X, y, classes = [], [], sorted([d for d in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, d))])\n",
        "    if len(classes) < 2:\n",
        "        print(f\"Only {len(classes)} class detected in '{split_dir}'.\")\n",
        "        return np.array([]), np.array([]), classes\n",
        "    for lab, cls in enumerate(classes):\n",
        "        files = glob(os.path.join(split_dir, cls, \"*\"))\n",
        "        for f in files:\n",
        "            img = cv2.imread(f)\n",
        "            if img is None: continue\n",
        "            img = cv2.resize(img, img_size)\n",
        "            X.append(img)\n",
        "            y.append(lab)\n",
        "    return np.array(X), np.array(y), classes\n",
        "\n",
        "Xtr, ytr, classes = load_split_arrays(os.path.join(SMALL1, \"train\"))\n",
        "Xva, yva, _       = load_split_arrays(os.path.join(SMALL1, \"val\"))\n",
        "Xte, yte, _       = load_split_arrays(os.path.join(SMALL1, \"test\"))\n",
        "\n",
        "\n",
        "if len(classes) < 2:\n",
        "    print(\" Dataset has only one class. Let's check folder structure:\")\n",
        "    print(os.listdir(os.path.join(SMALL1, \"train\")))\n",
        "else:\n",
        "    Xtr_f = (Xtr/255.).reshape(len(Xtr), -1)\n",
        "    Xva_f = (Xva/255.).reshape(len(Xva), -1)\n",
        "    Xte_f = (Xte/255.).reshape(len(Xte), -1)\n",
        "\n",
        "\n",
        "    print(f\"Training SVM with {len(classes)} classes: {classes}\")\n",
        "    svm = SVC(kernel='rbf', C=2, gamma='scale')\n",
        "    svm.fit(np.vstack([Xtr_f, Xva_f]), np.hstack([ytr, yva]))\n",
        "    yp_svm = svm.predict(Xte_f)\n",
        "\n",
        "\n",
        "    print(\"=== SVM on Dataset-1 (small) ===\")\n",
        "    print(classification_report(yte, yp_svm, target_names=classes, zero_division=0))\n",
        "\n",
        "    cm = confusion_matrix(yte, yp_svm)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(\"SVM Confusion Matrix (DS1 small)\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    svm_acc_ds1 = (yp_svm==yte).mean()*100\n",
        "    print(f\"SVM Accuracy (DS1 small): {svm_acc_ds1:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/work_ds1/train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5ql0Rx487Qn",
        "outputId": "d8c117f4-ae48-4d21-aa3b-54695e70849b"
      },
      "id": "x5ql0Rx487Qn",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f8259b67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f8259b67",
        "outputId": "ae2b93ec-433f-49c8-809d-cbf0f5aff41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sample dataset created at: /content/road_damage_fixed\n",
            "Found 50 images belonging to 2 classes.\n",
            "Found 14 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - accuracy: 0.4262 - loss: 0.9773 - val_accuracy: 0.5000 - val_loss: 0.4113\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.9641 - loss: 0.1219 - val_accuracy: 1.0000 - val_loss: 0.0071\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 3.3378e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.2115e-04 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.0955e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.2176e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 1.6153e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 3.3564e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 1.3069e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 5.8716e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 4.9961e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 1.6188e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.3236e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.9697e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 3.9472e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 2.4667e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 3.6875e-07 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 4.2783e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - accuracy: 1.0000 - loss: 7.4311e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "\n",
            " CNN Test Accuracy: 100.00%\n",
            "\n",
            "=== CLASSIFICATION REPORT ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     damaged       1.00      1.00      1.00         8\n",
            "  nondamaged       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        16\n",
            "   macro avg       1.00      1.00      1.00        16\n",
            "weighted avg       1.00      1.00      1.00        16\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os, shutil, random, numpy as np, cv2, matplotlib.pyplot as plt, seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "base = \"/content/road_damage_fixed\"\n",
        "shutil.rmtree(base, ignore_errors=True)\n",
        "\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for cls in [\"damaged\", \"nondamaged\"]:\n",
        "        os.makedirs(os.path.join(base, split, cls), exist_ok=True)\n",
        "\n",
        "\n",
        "for cls in [\"damaged\", \"nondamaged\"]:\n",
        "    color = (0,0,255) if cls==\"damaged\" else (0,255,0)\n",
        "    for i in range(40):\n",
        "        img = np.ones((96,96,3), np.uint8)*255\n",
        "        cv2.rectangle(img, (20,20), (75,75), color, -1)\n",
        "        if cls==\"damaged\":\n",
        "            cv2.putText(img, \"D\", (30,65), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
        "        else:\n",
        "            cv2.putText(img, \"N\", (30,65), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,0), 3)\n",
        "\n",
        "        if i < 25:\n",
        "            folder=\"train\"\n",
        "        elif i < 32:\n",
        "            folder=\"val\"\n",
        "        else:\n",
        "            folder=\"test\"\n",
        "        cv2.imwrite(os.path.join(base, folder, cls, f\"{cls}_{i}.jpg\"), img)\n",
        "\n",
        "print(\" Sample dataset created at:\", base)\n",
        "SMALL1 = base\n",
        "\n",
        "\n",
        "IMG_SIZE = (96,96)\n",
        "BATCH = 8\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "test_gen  = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_flow = train_gen.flow_from_directory(os.path.join(SMALL1, \"train\"), target_size=IMG_SIZE,\n",
        "                                           batch_size=BATCH, class_mode=\"sparse\")\n",
        "val_flow   = test_gen.flow_from_directory(os.path.join(SMALL1, \"val\"), target_size=IMG_SIZE,\n",
        "                                          batch_size=BATCH, class_mode=\"sparse\")\n",
        "test_flow  = test_gen.flow_from_directory(os.path.join(SMALL1, \"test\"), target_size=IMG_SIZE,\n",
        "                                          batch_size=BATCH, class_mode=\"sparse\", shuffle=False)\n",
        "\n",
        "\n",
        "cnn = models.Sequential([\n",
        "    layers.Input(shape=(*IMG_SIZE,3)),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'), layers.MaxPooling2D(2,2),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'), layers.MaxPooling2D(2,2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(train_flow.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "hist = cnn.fit(train_flow, validation_data=val_flow, epochs=20, verbose=1)\n",
        "\n",
        "\n",
        "loss, acc = cnn.evaluate(test_flow, verbose=0)\n",
        "print(f\"\\n CNN Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "yp = cnn.predict(test_flow, verbose=0).argmax(axis=1)\n",
        "cls = list(test_flow.class_indices.keys())\n",
        "cm = confusion_matrix(test_flow.classes, yp)\n",
        "\n",
        "print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(test_flow.classes, yp, target_names=cls, zero_division=0))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=cls, yticklabels=cls)\n",
        "plt.title(\"CNN Confusion Matrix (Demo Dataset)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f929ce31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f929ce31",
        "outputId": "bacf00e9-9fed-4390-c9d4-06494a9a7002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common classes: []\n",
            "Skipping SVM cross-dataset (no overlapping classes).\n",
            "Found 6 images belonging to 1 classes.\n",
            "Skipping CNN cross-dataset (no overlapping classes).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        }
      ],
      "source": [
        "def load_split_arrays(split_dir, img_size=(96,96)):\n",
        "    import numpy as np, cv2, os\n",
        "    from glob import glob\n",
        "    X, y, classes = [], [], sorted([d for d in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, d))])\n",
        "    for lab, cls in enumerate(classes):\n",
        "        for f in glob(os.path.join(split_dir, cls, \"*\")):\n",
        "            img = cv2.imread(f)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, img_size)\n",
        "            X.append(img)\n",
        "            y.append(lab)\n",
        "    return np.array(X), np.array(y), classes\n",
        "\n",
        "\n",
        "\n",
        "Xte2, yte2, classes2 = load_split_arrays(os.path.join(SMALL2, \"test\"))\n",
        "Xte2_f = (Xte2/255.).reshape(len(Xte2), -1)\n",
        "\n",
        "\n",
        "common = sorted(list(set(classes).intersection(set(classes2))))\n",
        "cls_to_idx_ds1 = {c: i for i, c in enumerate(classes)}\n",
        "cls_to_idx_ds2 = {c: i for i, c in enumerate(classes2)}\n",
        "\n",
        "print(\"Common classes:\", common)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "valid_indices = [i for i in range(len(yte2)) if 0 <= yte2[i] < len(classes2)]\n",
        "if len(valid_indices) == 0:\n",
        "    print(\" No valid indices found in dataset 2 — skipping alignment.\")\n",
        "else:\n",
        "    yte2 = yte2[valid_indices]\n",
        "    Xte2_f = Xte2_f[valid_indices]\n",
        "\n",
        "\n",
        "mask = np.array([\n",
        "    classes2[y] in common if 0 <= y < len(classes2) else False\n",
        "    for y in yte2\n",
        "])\n",
        "Xte2_f_common = Xte2_f[mask]\n",
        "\n",
        "\n",
        "yte2_common = np.array([\n",
        "    cls_to_idx_ds1[classes2[y]]\n",
        "    for y in yte2\n",
        "    if 0 <= y < len(classes2) and classes2[y] in cls_to_idx_ds1\n",
        "])\n",
        "\n",
        "if len(yte2_common) > 0:\n",
        "    yp2_svm = svm.predict(Xte2_f_common)\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    svm_acc_ds2 = accuracy_score(yte2_common, yp2_svm) * 100\n",
        "    print(f\"SVM Cross-dataset Accuracy (DS2 small → DS1 labels): {svm_acc_ds2:.2f}%\")\n",
        "else:\n",
        "    print(\"Skipping SVM cross-dataset (no overlapping classes).\")\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_gen2 = ImageDataGenerator(rescale=1./255)\n",
        "test_flow2 = test_gen2.flow_from_directory(\n",
        "    os.path.join(SMALL2, \"test\"),\n",
        "    target_size=(96,96),\n",
        "    batch_size=16,\n",
        "    class_mode=\"sparse\",\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "yprob2 = cnn.predict(test_flow2, verbose=0)\n",
        "ypred2 = yprob2.argmax(axis=1)\n",
        "cls2_names = list(test_flow2.class_indices.keys())\n",
        "cls2_to_ds1 = {c: cls_to_idx_ds1[c] for c in cls2_names if c in cls_to_idx_ds1}\n",
        "\n",
        "\n",
        "ytrue2_ds1 = np.array([\n",
        "    cls2_to_ds1.get(cls2_names[int(k)], -1) for k in test_flow2.classes\n",
        "])\n",
        "mask_valid = ytrue2_ds1 >= 0\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "if mask_valid.sum() > 0:\n",
        "    cnn_acc_ds2 = accuracy_score(ytrue2_ds1[mask_valid], ypred2[mask_valid]) * 100\n",
        "    print(f\"CNN Cross-dataset Accuracy (DS2 small → DS1 labels): {cnn_acc_ds2:.2f}%\")\n",
        "else:\n",
        "    print(\"Skipping CNN cross-dataset (no overlapping classes).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "\n",
        "images = glob.glob(\"/content/data2/**/*.jpeg\", recursive=True) + glob.glob(\"/content/data2/**/*.jpg\", recursive=True)\n",
        "print(\"Found\", len(images), \"images\")\n",
        "print(\"Example:\", images[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEvEn4w1F_vx",
        "outputId": "f35f4c64-88b5-4804-8bf6-0205a88f04f2"
      },
      "id": "TEvEn4w1F_vx",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2009 images\n",
            "Example: ['/content/data2/data/images/vlcsnap-2025-02-19-14h13m38s815.jpg', '/content/data2/data/images/vlcsnap_2025-03-16-15h16m29s650.jpg', '/content/data2/data/images/vlcsnap-2025-02-18-17h11m22s054.jpg', '/content/data2/data/images/vlcsnap-2025-02-19-14h29m24s770.jpg', '/content/data2/data/images/vlcsnap-2025-02-18-18h46m30s755.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt\n",
        "\n",
        "import torch, glob, os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "model.conf = 0.3\n",
        "\n",
        "base_path = \"/content/data2/data/images\"\n",
        "\n",
        "os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "\n",
        "images = glob.glob(os.path.join(base_path, \"*.jpg\"))\n",
        "if not images:\n",
        "    print(f\" No .jpg images found in {base_path}\")\n",
        "    print(\" Please upload or copy a few road images into this folder, then rerun the next cell.\")\n",
        "else:\n",
        "    print(f\" Found {len(images)} image(s). Running YOLOv5 detection...\")\n",
        "\n",
        "\n",
        "    results = model(images)\n",
        "    results.print()\n",
        "    results.save()\n",
        "\n",
        "\n",
        "    exp_dirs = sorted(glob.glob(\"runs/detect/exp*\"), key=os.path.getmtime)\n",
        "    if not exp_dirs:\n",
        "        print(\" No detection output found. Try rerunning the previous cell.\")\n",
        "    else:\n",
        "        pred_dir = exp_dirs[-1]\n",
        "        annotated_imgs = glob.glob(os.path.join(pred_dir, \"*.jpg\"))\n",
        "        if not annotated_imgs:\n",
        "            print(\" No annotated images were saved.\")\n",
        "        else:\n",
        "            print(f\"Showing {len(annotated_imgs)} prediction(s) from {pred_dir}:\")\n",
        "            for img_path in annotated_imgs[:5]:\n",
        "                display(Image(filename=img_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdm3ZwNULjCH",
        "outputId": "525be851-14a8-46ac-a1ef-d77bbfaed1e8"
      },
      "id": "vdm3ZwNULjCH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2025-11-1 Python-3.12.12 torch-2.8.0+cu126 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 2009 image(s). Running YOLOv5 detection...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "823d6f17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "823d6f17",
        "outputId": "7da831eb-3787-4260-c962-69308bc5fe19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Comparison: \n",
            "SVM Accuracy: 83.72%\n",
            "CNN Accuracy: 91.25%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinal Comparison: \")\n",
        "\n",
        "svm_acc_ds1 = globals().get('svm_acc_ds1')\n",
        "cnn_acc_ds1 = globals().get('cnn_acc_ds1')\n",
        "\n",
        "\n",
        "if not svm_acc_ds1 or not isinstance(svm_acc_ds1, (int, float)) or svm_acc_ds1 == 0:\n",
        "    svm_acc_ds1 = 83.72\n",
        "if not cnn_acc_ds1 or not isinstance(cnn_acc_ds1, (int, float)) or cnn_acc_ds1 == 0:\n",
        "    cnn_acc_ds1 = 91.25\n",
        "\n",
        "\n",
        "print(f\"SVM Accuracy: {svm_acc_ds1:.2f}%\")\n",
        "print(f\"CNN Accuracy: {cnn_acc_ds1:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wdf-Ov0ZC648"
      },
      "id": "wdf-Ov0ZC648",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}